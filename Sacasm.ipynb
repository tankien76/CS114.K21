{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xmm8XsozaGq_khs_fcMBLay9_V38LNhw",
      "authorship_tag": "ABX9TyM2q9kVnu/uiDYh4ZbUE+OY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tankien76/CS114.K21/blob/master/Sacasm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdIYFu-hWqPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6ab26b45-c96d-44b8-f1dd-fe5776c0cc9d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG8IK2-VMmBM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b3677d2-7cb4-4bbf-8e62-7ff5b1ec7f79"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBkBZNYhV7Gh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d40bdd92-8af0-4634-d108-faba13cd179a"
      },
      "source": [
        "cd drive/My Drive/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiBa9uuyV-nH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd, numpy as np, re, time\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED_Q5m7sc46x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VynDT62JWWyQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "dfccb368-0279-4ce9-cb41-6b6ff22fc9a8"
      },
      "source": [
        "# Loading data from json file\n",
        "data = pd.read_json(\"Sarcasm_Headlines_Dataset_v2.json\", lines = True)\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "      <th>article_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dem rep. totally nails why congress is falling...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mother comes pretty close to using word 'strea...</td>\n",
              "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_sarcastic  ...                                       article_link\n",
              "0             1  ...  https://www.theonion.com/thirtysomething-scien...\n",
              "1             0  ...  https://www.huffingtonpost.com/entry/donna-edw...\n",
              "2             0  ...  https://www.huffingtonpost.com/entry/eat-your-...\n",
              "3             1  ...  https://local.theonion.com/inclement-weather-p...\n",
              "4             1  ...  https://www.theonion.com/mother-comes-pretty-c...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4moVlFdWaU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting features and labels\n",
        "features = data['headline']\n",
        "labels = data['is_sarcastic']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esMiO4huV_1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Relacing special symbols and digits in headline column\n",
        "# re stands for Regular Expression\n",
        "features = features.apply(lambda s : re.sub('[^a-zA-Z]', ' ', s))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfEjGyOzWKhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stemming our data\n",
        "ps = PorterStemmer()\n",
        "features = features.apply(lambda x: x.split())\n",
        "features = features.apply(lambda x : ' '.join([ps.stem(word) for word in x]))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yApR9V3eWiJf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "99c4fb75-1eb5-40a9-e602-a75913bc6e23"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfIdfVec = TfidfVectorizer()\n",
        "tfIdfVec.fit(features)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF-2kZEtdUlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_idf_x = tfIdfVec.transform(features)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYRz_4q5Wz4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting training and testing data\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(tf_idf_x.todense(), labels, test_size = .1, random_state = 0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJN-cfgLW1Sp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "29df0888-f3f1-4d5f-a696-399987a76cea"
      },
      "source": [
        "# Using linear support vector classifier\n",
        "lsvc = LinearSVC()\n",
        "# training the model\n",
        "lsvc.fit(features_train, labels_train)\n",
        "# getting the score of train and test data\n",
        "print(\"Train accuracy: \",lsvc.score(features_train, labels_train))\n",
        "print(\"Test accuracy: \",lsvc.score(features_test, labels_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy:  0.9538377916682843\n",
            "Test accuracy:  0.8371767994409504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-81u9fBod6FC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# rfc = RandomForestClassifier(n_estimators=500,random_state=42)\n",
        "# rfc.fit(features_train,labels_train)\n",
        "# preds = rfc.predict(features_test)\n",
        "# print('accuracy: ', accuracy_score(labels_test,preds))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R43qj7AvW3qv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "777d6222-7416-4fa1-f789-ac8c53d3d403"
      },
      "source": [
        "# Loading data from json file\n",
        "data1 = pd.read_json(\"dataset.json\", lines = True, encoding='cp1252' )\n",
        "data1.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "      <th>article_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>The Police Officers Who Killed Breonna Taylor ...</td>\n",
              "      <td>https://www.huffingtonpost.co.uk/entry/police-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Scientists Discover Mysterious Radio Transmiss...</td>\n",
              "      <td>https://www.theonion.com/scientists-discover-m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Historic Anti-Lynching Legislation Blocked In ...</td>\n",
              "      <td>https://www.huffingtonpost.co.uk/entry/histori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Democratic Leaders Announce That Theyâ€™ve Learn...</td>\n",
              "      <td>https://politics.theonion.com/democratic-leade...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Will A Coronavirus Vaccine Really Be 'Availabl...</td>\n",
              "      <td>https://www.huffingtonpost.co.uk/entry/coronav...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_sarcastic  ...                                       article_link\n",
              "0             0  ...  https://www.huffingtonpost.co.uk/entry/police-...\n",
              "1             1  ...  https://www.theonion.com/scientists-discover-m...\n",
              "2             0  ...  https://www.huffingtonpost.co.uk/entry/histori...\n",
              "3             1  ...  https://politics.theonion.com/democratic-leade...\n",
              "4             0  ...  https://www.huffingtonpost.co.uk/entry/coronav...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsHhxbdkW4nY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_val = data1['headline']\n",
        "labels_val = data1['is_sarcastic']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj9hH-PhW_u4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stemming our data\n",
        "ps1 = PorterStemmer()\n",
        "features_val = features_val.apply(lambda x: x.split())\n",
        "features_val = features_val.apply(lambda x : ' '.join([ps.stem(word) for word in x]))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L82W8REXcoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tv1 = tfIdfVec\n",
        "#features_val = list(features_val)\n",
        "features_val = tv1.transform(features_val).toarray()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw9kqkC9Xk73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b2cd600-ef5e-4864-e8e5-44db6c06cc6e"
      },
      "source": [
        "# getting the score of train and test data\n",
        "print(\"Val accuracy: \",lsvc.score(features_val, labels_val))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Val accuracy:  0.7770853307766059\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}